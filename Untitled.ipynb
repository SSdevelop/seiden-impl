{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2636401f-d8eb-44d1-8b3b-29c56eaa3ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, GroundingDinoForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef1b1fe-ba15-4cde-9c1b-ebed8c2a5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyframes(video_path):\n",
    "    container = av.open(video_path)\n",
    "    stream = container.streams.video[0]\n",
    "    frame_index = 0\n",
    "    keyframe_index = []\n",
    "    keyframes = []\n",
    "    for frame in container.decode(stream):\n",
    "        if frame_index == 0 or frame.key_frame:\n",
    "            frame_data = frame.to_ndarray(format='rgb24')\n",
    "            keyframes.append(frame_data)\n",
    "            keyframe_index.append(frame_index)\n",
    "        frame_index += 1\n",
    "    container.close()\n",
    "    return keyframe_index, np.array(keyframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3ec039-13ad-44c1-8c71-b6b393eb4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframe_index, keyframe = extract_keyframes('input_videos/hong_kong_airport_demo_data.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd952572-b7e0-401c-b5e0-d491636c4533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 44, 196, 348, 500, 652, 804, 956, 1108, 1260, 1412, 1564, 1716, 1868, 2020, 2172, 2324, 2476, 2628]\n"
     ]
    }
   ],
   "source": [
    "print(keyframe_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "398f422e-786e-4f4c-84c1-3696b77e1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_keyframes(keyframe_index, keyframes, sampling_ratio):\n",
    "    num_samples = int(len(keyframe_index) * sampling_ratio)\n",
    "    sampled_indices = np.linspace(0, len(keyframe_index)-1, num_samples, dtype=int)\n",
    "    keyframe_samples = keyframes[sampled_indices]\n",
    "    keyframe_index_samples = [keyframe_index[i] for i in sampled_indices]\n",
    "    return keyframe_index_samples, keyframe_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62627f9a-08ee-4d91-a8f8-d927013b882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_keyframe_indices, sampled_keyframes = sample_keyframes(keyframe_index, keyframe, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a143392d-9905-4949-ba66-4fc13f8b56c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[139, 130, 126],\n",
       "         [139, 130, 126],\n",
       "         [139, 130, 126],\n",
       "         ...,\n",
       "         [148, 137, 122],\n",
       "         [140, 129, 114],\n",
       "         [151, 140, 125]],\n",
       "\n",
       "        [[ 97,  88,  84],\n",
       "         [ 97,  88,  84],\n",
       "         [ 97,  88,  84],\n",
       "         ...,\n",
       "         [145, 134, 119],\n",
       "         [149, 138, 123],\n",
       "         [151, 140, 125]],\n",
       "\n",
       "        [[ 82,  73,  69],\n",
       "         [ 82,  73,  69],\n",
       "         [ 82,  73,  69],\n",
       "         ...,\n",
       "         [148, 137, 122],\n",
       "         [149, 138, 123],\n",
       "         [132, 121, 106]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[154, 139, 119],\n",
       "         [154, 139, 119],\n",
       "         [154, 139, 119],\n",
       "         ...,\n",
       "         [137, 179, 227],\n",
       "         [136, 178, 235],\n",
       "         [136, 178, 235]],\n",
       "\n",
       "        [[154, 139, 119],\n",
       "         [154, 139, 119],\n",
       "         [154, 139, 119],\n",
       "         ...,\n",
       "         [134, 179, 235],\n",
       "         [134, 178, 241],\n",
       "         [134, 178, 241]],\n",
       "\n",
       "        [[154, 139, 119],\n",
       "         [154, 139, 119],\n",
       "         [154, 139, 119],\n",
       "         ...,\n",
       "         [133, 178, 234],\n",
       "         [134, 178, 241],\n",
       "         [134, 178, 241]]],\n",
       "\n",
       "\n",
       "       [[[104,  98,  93],\n",
       "         [104,  98,  93],\n",
       "         [104,  98,  93],\n",
       "         ...,\n",
       "         [149, 138, 121],\n",
       "         [149, 138, 121],\n",
       "         [149, 138, 121]],\n",
       "\n",
       "        [[ 93,  87,  82],\n",
       "         [ 93,  87,  82],\n",
       "         [ 93,  87,  82],\n",
       "         ...,\n",
       "         [149, 138, 121],\n",
       "         [149, 138, 121],\n",
       "         [149, 138, 121]],\n",
       "\n",
       "        [[ 85,  79,  74],\n",
       "         [ 85,  79,  74],\n",
       "         [ 85,  79,  74],\n",
       "         ...,\n",
       "         [149, 138, 121],\n",
       "         [149, 138, 121],\n",
       "         [149, 138, 121]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[160, 146, 128],\n",
       "         [160, 146, 128],\n",
       "         [161, 147, 129],\n",
       "         ...,\n",
       "         [ 23,  22,  27],\n",
       "         [ 23,  22,  27],\n",
       "         [ 23,  22,  27]],\n",
       "\n",
       "        [[157, 143, 125],\n",
       "         [157, 143, 125],\n",
       "         [157, 143, 125],\n",
       "         ...,\n",
       "         [ 22,  21,  26],\n",
       "         [ 23,  22,  27],\n",
       "         [ 23,  22,  27]],\n",
       "\n",
       "        [[164, 150, 132],\n",
       "         [163, 149, 131],\n",
       "         [161, 147, 129],\n",
       "         ...,\n",
       "         [ 22,  21,  26],\n",
       "         [ 22,  21,  26],\n",
       "         [ 22,  21,  26]]],\n",
       "\n",
       "\n",
       "       [[[169, 158, 143],\n",
       "         [169, 158, 143],\n",
       "         [169, 158, 143],\n",
       "         ...,\n",
       "         [181, 172, 157],\n",
       "         [181, 172, 157],\n",
       "         [181, 172, 157]],\n",
       "\n",
       "        [[168, 157, 142],\n",
       "         [168, 157, 142],\n",
       "         [168, 157, 142],\n",
       "         ...,\n",
       "         [181, 172, 157],\n",
       "         [181, 172, 157],\n",
       "         [181, 172, 157]],\n",
       "\n",
       "        [[167, 156, 141],\n",
       "         [167, 156, 141],\n",
       "         [167, 156, 141],\n",
       "         ...,\n",
       "         [181, 172, 157],\n",
       "         [181, 172, 157],\n",
       "         [181, 172, 157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 92,  84,  90],\n",
       "         [ 92,  84,  90],\n",
       "         [ 92,  84,  90],\n",
       "         ...,\n",
       "         [ 92,  86,  81],\n",
       "         [ 91,  85,  80],\n",
       "         [ 91,  85,  80]],\n",
       "\n",
       "        [[ 91,  83,  89],\n",
       "         [ 91,  83,  89],\n",
       "         [ 91,  83,  89],\n",
       "         ...,\n",
       "         [ 92,  86,  81],\n",
       "         [ 92,  86,  81],\n",
       "         [ 92,  86,  81]],\n",
       "\n",
       "        [[ 91,  83,  89],\n",
       "         [ 91,  83,  89],\n",
       "         [ 91,  83,  89],\n",
       "         ...,\n",
       "         [ 92,  86,  81],\n",
       "         [ 92,  86,  81],\n",
       "         [ 92,  86,  81]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[197, 187, 163],\n",
       "         [187, 177, 153],\n",
       "         [174, 164, 140],\n",
       "         ...,\n",
       "         [103,  92,  85],\n",
       "         [104,  93,  86],\n",
       "         [104,  93,  86]],\n",
       "\n",
       "        [[198, 188, 164],\n",
       "         [192, 182, 158],\n",
       "         [170, 160, 136],\n",
       "         ...,\n",
       "         [103,  92,  85],\n",
       "         [104,  93,  86],\n",
       "         [104,  93,  86]],\n",
       "\n",
       "        [[195, 185, 161],\n",
       "         [194, 184, 160],\n",
       "         [175, 165, 141],\n",
       "         ...,\n",
       "         [103,  92,  85],\n",
       "         [104,  93,  86],\n",
       "         [104,  93,  86]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[143, 127, 110],\n",
       "         [156, 140, 123],\n",
       "         [166, 150, 133],\n",
       "         ...,\n",
       "         [120, 108,  96],\n",
       "         [127, 115, 103],\n",
       "         [133, 121, 109]],\n",
       "\n",
       "        [[135, 119, 102],\n",
       "         [148, 132, 115],\n",
       "         [158, 142, 125],\n",
       "         ...,\n",
       "         [128, 116, 104],\n",
       "         [133, 121, 109],\n",
       "         [141, 129, 117]],\n",
       "\n",
       "        [[136, 120, 103],\n",
       "         [147, 131, 114],\n",
       "         [152, 136, 119],\n",
       "         ...,\n",
       "         [132, 120, 108],\n",
       "         [130, 118, 106],\n",
       "         [132, 120, 108]]],\n",
       "\n",
       "\n",
       "       [[[154, 142, 132],\n",
       "         [154, 142, 132],\n",
       "         [154, 142, 132],\n",
       "         ...,\n",
       "         [183, 167, 163],\n",
       "         [183, 167, 163],\n",
       "         [183, 167, 163]],\n",
       "\n",
       "        [[154, 142, 132],\n",
       "         [154, 142, 132],\n",
       "         [154, 142, 132],\n",
       "         ...,\n",
       "         [190, 174, 170],\n",
       "         [190, 174, 170],\n",
       "         [190, 174, 170]],\n",
       "\n",
       "        [[154, 142, 132],\n",
       "         [154, 142, 132],\n",
       "         [154, 142, 132],\n",
       "         ...,\n",
       "         [187, 172, 163],\n",
       "         [187, 172, 163],\n",
       "         [187, 172, 163]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[154, 153, 144],\n",
       "         [147, 146, 137],\n",
       "         [148, 147, 138],\n",
       "         ...,\n",
       "         [140, 129, 110],\n",
       "         [137, 126, 109],\n",
       "         [137, 126, 109]],\n",
       "\n",
       "        [[157, 156, 147],\n",
       "         [151, 150, 141],\n",
       "         [117, 116, 107],\n",
       "         ...,\n",
       "         [147, 136, 117],\n",
       "         [142, 131, 114],\n",
       "         [144, 133, 116]],\n",
       "\n",
       "        [[152, 151, 142],\n",
       "         [125, 124, 115],\n",
       "         [ 61,  60,  51],\n",
       "         ...,\n",
       "         [142, 131, 112],\n",
       "         [138, 127, 110],\n",
       "         [140, 129, 112]]],\n",
       "\n",
       "\n",
       "       [[[ 85,  76,  70],\n",
       "         [ 85,  76,  70],\n",
       "         [ 85,  76,  70],\n",
       "         ...,\n",
       "         [113,  97,  80],\n",
       "         [107,  91,  74],\n",
       "         [110,  94,  77]],\n",
       "\n",
       "        [[ 85,  76,  70],\n",
       "         [ 85,  76,  70],\n",
       "         [ 85,  76,  70],\n",
       "         ...,\n",
       "         [168, 152, 135],\n",
       "         [148, 132, 115],\n",
       "         [127, 111,  94]],\n",
       "\n",
       "        [[ 84,  75,  69],\n",
       "         [ 84,  75,  69],\n",
       "         [ 84,  75,  69],\n",
       "         ...,\n",
       "         [170, 154, 137],\n",
       "         [172, 156, 139],\n",
       "         [175, 159, 142]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[128, 118, 108],\n",
       "         [125, 115, 105],\n",
       "         [122, 112, 102],\n",
       "         ...,\n",
       "         [  9,   8,  11],\n",
       "         [  9,   8,  11],\n",
       "         [  9,   8,  11]],\n",
       "\n",
       "        [[128, 118, 108],\n",
       "         [125, 115, 105],\n",
       "         [123, 113, 103],\n",
       "         ...,\n",
       "         [  9,   8,  11],\n",
       "         [  9,   8,  11],\n",
       "         [  9,   8,  11]],\n",
       "\n",
       "        [[128, 118, 108],\n",
       "         [125, 115, 105],\n",
       "         [123, 113, 103],\n",
       "         ...,\n",
       "         [  9,   8,  11],\n",
       "         [  9,   8,  11],\n",
       "         [  9,   8,  11]]]], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a0e47b6-efe9-46d3-88a1-1548652a1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('iframes', exist_ok=True)\n",
    "for i, frame in enumerate(sampled_keyframes):\n",
    "    img = Image.fromarray(frame)\n",
    "    output_path = os.path.join(f'iframes/iframe_{i}.jpg')\n",
    "    img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3455e17-8790-4348-8988-6c77f58efee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Could not load the custom kernel for multi-scale deformable attention: Error building extension 'MultiScaleDeformableAttention': [1/4] c++ -MMD -MF ms_deform_attn_cpu.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/TH -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/THC -isystem /home/srijan/.conda/envs/seiden/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DWITH_CUDA=1 -c /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.cpp -o ms_deform_attn_cpu.o \n",
      "[2/4] c++ -MMD -MF vision.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/TH -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/THC -isystem /home/srijan/.conda/envs/seiden/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DWITH_CUDA=1 -c /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/vision.cpp -o vision.o \n",
      "In file included from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/vision.cpp:11:\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/ms_deform_attn.h: In function ‘at::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)’:\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/ms_deform_attn.h:29:19: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   29 |     if (value.type().is_cuda())\n",
      "      |         ~~~~~~~~~~^~\n",
      "In file included from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/extension.h:5,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.h:12,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/ms_deform_attn.h:13,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/vision.cpp:11:\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "  225 |   DeprecatedTypeProperties & type() const {\n",
      "      |                              ^~~~\n",
      "In file included from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/vision.cpp:11:\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/ms_deform_attn.h: In function ‘std::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)’:\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/ms_deform_attn.h:51:19: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "   51 |     if (value.type().is_cuda())\n",
      "      |         ~~~~~~~~~~^~\n",
      "In file included from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/extension.h:5,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.h:12,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/ms_deform_attn.h:13,\n",
      "                 from /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/vision.cpp:11:\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "  225 |   DeprecatedTypeProperties & type() const {\n",
      "      |                              ^~~~\n",
      "[3/4] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/TH -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/THC -isystem /home/srijan/.conda/envs/seiden/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o \n",
      "\u001b[31mFAILED: \u001b[0mms_deform_attn_cuda.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/TH -isystem /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/torch/include/THC -isystem /home/srijan/.conda/envs/seiden/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o \n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu:19:9: warning: #pragma once in main file\n",
      "   19 | #pragma once\n",
      "      |         ^~~~\n",
      "/home/srijan/.conda/envs/seiden/lib/python3.12/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu:19:9: warning: #pragma once in main file\n",
      "   19 | #pragma once\n",
      "      |         ^~~~\n",
      "sh: 1: cicc: not found\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/srijan/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"IDEA-Research/grounding-dino-base\")\n",
    "model = GroundingDinoForObjectDetection.from_pretrained(\"IDEA-Research/grounding-dino-base\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6948c855-932b-4c4e-bd89-d848e82d8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(model, processor, sampled_keyframes, sampled_keyframe_indices, device='cuda'):\n",
    "\n",
    "    index = {}\n",
    "    for i, frame in enumerate(sampled_keyframes):\n",
    "        # print(frame.shape[:2])\n",
    "        inputs = processor(images=frame, text='pink suitcase', return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        result = processor.post_process_grounded_object_detection(\n",
    "            outputs,\n",
    "            inputs.input_ids,\n",
    "            box_threshold=0.3,\n",
    "            text_threshold=0.2,\n",
    "            target_sizes=torch.tensor([[frame.shape[0], frame.shape[1]]])\n",
    "        )\n",
    "        # print(result)\n",
    "        index[sampled_keyframe_indices[i]] = result[0]['scores'].cpu()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "428d6463-142b-4e27-ba8b-167691e40e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = create_index(model, processor, sampled_keyframes, sampled_keyframe_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fe7364e-9fc3-4f98-8a1c-ecb857fd969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([]), 44: tensor([]), 196: tensor([]), 348: tensor([]), 500: tensor([0.3449, 0.3505]), 652: tensor([]), 804: tensor([]), 956: tensor([]), 1108: tensor([]), 1260: tensor([0.3317, 0.3119]), 1412: tensor([]), 1564: tensor([0.3447]), 1716: tensor([]), 1868: tensor([]), 2020: tensor([0.3149]), 2172: tensor([0.3240]), 2324: tensor([]), 2476: tensor([0.3049]), 2628: tensor([])}\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec730f-250e-4cba-9f00-0a072e92692e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
